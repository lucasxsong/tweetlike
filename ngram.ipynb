{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import json\n",
    "from collections import Counter\n",
    "import random\n",
    "import re\n",
    " \n",
    "# \"...\" -> {...}\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(data.split(' '), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "# remove urls\n",
    "def clean_text(txt):\n",
    "    # remove urls\n",
    "    txt = re.sub(r\"https://[A-Za-z]+.[A-Za-z]*\", '',txt)\n",
    "#     txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "# generates a sentence seed\n",
    "def startsent(bigrams):\n",
    "    beg = []\n",
    "    for b in bigrams:\n",
    "        first = b.split(' ')[0]\n",
    "        # TO DO: CHANGE CHOOSE CONDITION DYNAMICALLY BASED ON FILE SIZE\n",
    "        if (first == \"begsent\" and bigrams[b] > 1):\n",
    "            beg.append(b)\n",
    "            \n",
    "    return random.choice(beg)\n",
    "\n",
    "# gets the next word given the previous\n",
    "# random choice from 10 most popular ngrams\n",
    "def getword(word, bigrams):\n",
    "    possiblewords = []\n",
    "    newword=\"\"\n",
    "    \n",
    "    for b in bigrams:\n",
    "        first = b.split(' ')[0]\n",
    "        \n",
    "        # don't want to add too irrelevant bigrams to choose from\n",
    "        if(len(possiblewords) > 10): break;\n",
    "        # TO DO: CHANGE CHOOSE CONDITION DYNAMICALLY BASED ON FILE SIZE\n",
    "        if (first == word and bigrams[b] > 0):\n",
    "            newword = b.split(' ')[1]\n",
    "            possiblewords.append(newword)\n",
    "\n",
    "    if (len(possiblewords) == 0):\n",
    "        return \"\"\n",
    "    else:\n",
    "        newword = random.choice(possiblewords)\n",
    "        if(newword == \"endsent\"): return \"\"\n",
    "        else: return newword\n",
    "    \n",
    "\n",
    "def word_gen(bigrams):\n",
    "    seed = startsent(bigrams)\n",
    "    sent = seed.split(' ')[1]\n",
    "    \n",
    "    nextword = getword(sent, bigrams)\n",
    "    while (nextword != \"\" and len(sent) < 140):\n",
    "        sent += \" \" + nextword\n",
    "        nextword = getword(nextword, bigrams)\n",
    "        \n",
    "    # if too many @'s, retry\n",
    "    if(len(re.findall('@', sent)) == len(sent.split(' '))):\n",
    "       sent = word_gen(bigrams)\n",
    "    \n",
    "    return sent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "### takin an n grams approach ###\n",
    "def writengrams(city):\n",
    "    with open(\"cities/\" + city, \"r\") as content:\n",
    "        data = json.load(content)\n",
    "\n",
    "    all_tweets = []\n",
    "    for tweet in data:\n",
    "        updatetweet = \"begsent \" + tweet['tweet'][0]['text'] + \" endsent\"\n",
    "        all_tweets.append(updatetweet)\n",
    "\n",
    "    all_tweets = [h for h in all_tweets if h != \"Unknown\"]\n",
    "\n",
    "    corpus = [clean_text(x) for x in all_tweets]\n",
    "\n",
    "    bigrams = {}\n",
    "\n",
    "    for tweet in corpus:\n",
    "        bigram = extract_ngrams(tweet.lower(), 2)\n",
    "        for b in bigram:\n",
    "            if b in bigrams:\n",
    "                bigrams[b] +=1\n",
    "            else:\n",
    "                bigrams[b] = 1\n",
    "            \n",
    "    sortedbigrams = {k: v for k, v in sorted(bigrams.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    with open(\"ngramsbycity/\" + city, 'w') as file:\n",
    "        file.write(json.dumps(sortedbigrams))\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(Counter(allngs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE TWEETS -> NGRAM FILES ###\n",
    "\n",
    "# cityfile = open('writtencities', \"r\")\n",
    "# cities = json.load(cityfile)\n",
    "\n",
    "# for f in cities:\n",
    "#     city = re.sub(\" \", \"\", f.split(',')[0].lower())\n",
    "#     writengrams(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ngramsbycity/mexico'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1204-1ef5f96e541b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ngramsbycity/mexico\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbgrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(bgrams)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ngramsbycity/mexico'"
     ]
    }
   ],
   "source": [
    "ifile = open(\"ngramsbycity/d = defaultdict(list)\")\n",
    "bgrams = json.load(ifile)\n",
    "\n",
    "# print(bgrams)\n",
    "\n",
    "print(word_gen(bgrams))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
